{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The SIFT & SURF algorithms are patented by their respective creators, and while they are free to use in academic and research settings, you should technically be obtaining a license/permission from the creators if you are using them in a commercial (i.e. for-profit) application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv_contrib\\modules\\xfeatures2d\\src\\surf.cpp:1029: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e1b8cc4cc1ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[0mipv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeMapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m     \u001b[0mipv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImageInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Mapping Matrix:\\n {t}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-e1b8cc4cc1ed>\u001b[0m in \u001b[0;36mcomputeMapping\u001b[1;34m(leftImage, rightImage)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# surf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0msurf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mleftKeypoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleftDescriptors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleftGrey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mrightKeypoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrightDescriptors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrightGrey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv_contrib\\modules\\xfeatures2d\\src\\surf.cpp:1029: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cv2\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "class ImageInfo:\n",
    "    def __init__(self, name, img, position):\n",
    "        self.name = name\n",
    "        self.img = img\n",
    "        self.position = position\n",
    "\n",
    "def computeMapping(leftImage, rightImage):\n",
    "    leftGrey = cv2.cvtColor(leftImage, cv2.COLOR_BGR2GRAY)\n",
    "    rightGrey = cv2.cvtColor(rightImage, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # surf\n",
    "    surf = cv2.xfeatures2d.SURF_create()\n",
    "    leftKeypoints, leftDescriptors = surf.detectAndCompute(leftGrey, None)\n",
    "    rightKeypoints, rightDescriptors = surf.detectAndCompute(rightGrey, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L1,crossCheck=False)\n",
    "    \n",
    "    # # sift\n",
    "    # sift = cv2.xfeatures2d.SIFT_create()\n",
    "    # leftKeypoints, leftDescriptors = sift.detectAndCompute(leftGrey, None)\n",
    "    # rightKeypoints, rightDescriptors = sift.detectAndCompute(rightGrey, None)\n",
    "    # bf = cv2.BFMatcher(cv2.NORM_L1,crossCheck=False)\n",
    "    \n",
    "    # # orb\n",
    "    # orb = cv2.ORB_create(nfeatures=1500)\n",
    "    # leftKeypoints, leftDescriptors = orb.detectAndCompute(leftGrey, None)\n",
    "    # rightKeypoints, rightDescriptors = orb.detectAndCompute(rightGrey, None)\n",
    "    # bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    \n",
    "    matches = bf.match(leftDescriptors, rightDescriptors)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "    # Minimize matches\n",
    "    nMatches = int( 20 * len(matches) / 100)\n",
    "    if nMatches < 4:\n",
    "        return None\n",
    "    matches = matches[:nMatches]\n",
    "    motionModel = 1\n",
    "    nRANSAC = 500\n",
    "    RANSACThreshold = 0.1\n",
    "\n",
    "    alignMatrix,inmatches = alignPair(leftKeypoints, rightKeypoints, matches, motionModel, nRANSAC, RANSACThreshold) \n",
    "    print(f'* Matches: {len(inmatches)}')\n",
    "    # Map feature pts in both images\n",
    "    img3 = cv2.drawMatches(leftGrey,leftKeypoints,rightGrey,rightKeypoints,inmatches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    cv2.namedWindow('Features', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('Features',img3)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # # Map inliers\n",
    "    # img3 = cv2.drawMatches(leftGrey,leftKeypoints,rightGrey,rightKeypoints,inlier_indices,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    # cv2.namedWindow('Inliers', cv2.WINDOW_NORMAL)\n",
    "    # cv2.imshow('Inliers',img3)\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    return alignMatrix\n",
    "\n",
    "def alignPair(f1, f2, matches, m, nRANSAC, RANSACthresh):\n",
    "    Sample_size = 4\n",
    "    max_inlier = 0\n",
    "    count_inlier = []\n",
    "\n",
    "    for i in range(nRANSAC):\n",
    "        H = np.eye(3)\n",
    "        randMatch = np.random.choice(matches, Sample_size)\n",
    "        H = computeHomography(f1,f2,randMatch)\n",
    "\n",
    "        num_inliers = getInliers(f1, f2, matches, H, RANSACthresh)\n",
    "        if len(num_inliers) > max_inlier:\n",
    "            count_inlier = num_inliers\n",
    "            max_inlier = len(num_inliers)\n",
    "\n",
    "        M,inmatches = leastSquaresFit(f1, f2, matches, m, count_inlier)\n",
    "    # print(f'* M,inmatches: {M, len(inmatches)}')\n",
    "    return M,inmatches\n",
    "\n",
    "def computeHomography(f1, f2, matches, A_out=None):\n",
    "    num_matches = len(matches)\n",
    "    # Dimensions of the A matrix in the homogenous linear equation Ah = 0\n",
    "    num_rows = 2 * num_matches\n",
    "    num_cols = 9\n",
    "    A_matrix_shape = (num_rows,num_cols)\n",
    "    A = np.zeros(A_matrix_shape)\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        m = matches[i]\n",
    "        (a_x, a_y) = f1[m.queryIdx].pt\n",
    "        (b_x, b_y) = f2[m.trainIdx].pt\n",
    "\n",
    "        #Fill in the matrix A in this loop.\n",
    "        #Access elements using square brackets. e.g. A[0,0]\n",
    "        A[2*i, 0] = a_x\n",
    "        A[2*i, 1] = a_y\n",
    "        A[2*i, 2] = 1\n",
    "        A[2*i, 3] = 0\n",
    "        A[2*i, 4] = 0\n",
    "        A[2*i, 5] = 0\n",
    "        A[2*i, 6] = -b_x * a_x\n",
    "        A[2*i, 7] = -b_x * a_y\n",
    "        A[2*i, 8] = -b_x\n",
    "\n",
    "        A[2*i+1,0] = 0\n",
    "        A[2*i+1,1] = 0\n",
    "        A[2*i+1,2] = 0\n",
    "        A[2*i+1,3] = a_x\n",
    "        A[2*i+1,4] = a_y\n",
    "        A[2*i+1,5] = 1\n",
    "        A[2*i+1,6] = -b_y * a_x\n",
    "        A[2*i+1,7] = -b_y * a_y\n",
    "        A[2*i+1,8] = -b_y\n",
    "\n",
    "    U, s, Vt = np.linalg.svd(A)\n",
    "\n",
    "    if A_out is not None:\n",
    "        A_out[:] = A\n",
    "\n",
    "    #s is a 1-D array of singular values sorted in descending order\n",
    "    #U, Vt are unitary matrices\n",
    "    #Rows of Vt are the eigenvectors of A^TA.\n",
    "    #Columns of U are the eigenvectors of AA^T.\n",
    "\n",
    "    #Homography to be calculated\n",
    "    H = np.eye(3)\n",
    "\n",
    "    #Fill the homography H with the appropriate elements of the SVD\n",
    "    minsv = Vt.shape[0] - 1\n",
    "    H = (Vt[minsv] / Vt[minsv][8]).reshape(3,3)\n",
    "\n",
    "    return H\n",
    "\n",
    "def getInliers(f1, f2, matches, M, RANSACthresh):\n",
    "    inlier_indices = []\n",
    "\n",
    "    for i in range(len(matches)):\n",
    "        #Determine if the ith matched feature f1[id1], when transformed\n",
    "        #by M, is within RANSACthresh of its match in f2.\n",
    "        #If so, append i to inliers\n",
    "        # features\n",
    "        m = matches[i]\n",
    "        (a_x, a_y) = f1[m.queryIdx].pt\n",
    "        (b_x, b_y) = f2[m.trainIdx].pt\n",
    "\n",
    "        # Transform \n",
    "        p = np.zeros(3)\n",
    "        p[0] = a_x\n",
    "        p[1] = a_y\n",
    "        p[2] = 1\n",
    "        translated = np.dot(M , p)\n",
    "        xt = translated[0] / translated[2]\n",
    "        yt = translated[1] / translated[2]\n",
    "\n",
    "        # Euclidean distance\n",
    "        x_diff = (b_x - xt) * (b_x - xt)\n",
    "        y_diff = (b_y - yt) * (b_y - yt)\n",
    "        distance = np.sqrt(x_diff + y_diff)\n",
    "        if distance <= RANSACthresh:\n",
    "        \tinlier_indices.append(i)\n",
    "    # print(f'*: Inliers: {len(inlier_indices)}')\n",
    "    return inlier_indices\n",
    "\n",
    "def leastSquaresFit(f1, f2, matches, m, inlier_indices):\n",
    "    # This function needs to handle two possible motion models,\n",
    "    # pure translations (eTranslate)\n",
    "    # and full homographies (eHomography).\n",
    "    M = np.eye(3)\n",
    "        #Compute a homography M using all inliers.\n",
    "        #This should call computeHomography.\n",
    "    inmatches = []\n",
    "    for i in range(len(inlier_indices)):\n",
    "        inmatches.append(matches[inlier_indices[i]])\n",
    "    M = computeHomography(f1,f2,inmatches)\n",
    "    return M,inmatches\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     images = [cv2.imread('yosemite1.jpg'), cv2.imread('yosemite2.jpg')]\n",
    "#     t = computeMapping(images[0], images[1])#.dot(t)\n",
    "#     print(t)\n",
    "\n",
    "\n",
    "def blendImages(ipv, blendWidth=70, is360=False, A_out=None):\n",
    "    accWidth, accHeight, channels, width, translation = getAccSize(ipv)\n",
    "    acc = pasteImages(ipv, translation, blendWidth, accWidth, accHeight, channels)\n",
    "    compImage = normalizeBlend(acc)\n",
    "    # print(f'*: Normalized Image: {compImage}')\n",
    "    cv2.imwrite('compImage.jpg',compImage)\n",
    "\n",
    "    # Determine the final image width\n",
    "    outputWidth = accWidth\n",
    "    x_init, y_init, x_final, y_final = getDriftParams(ipv, translation, width)\n",
    "    # Compute the affine transform\n",
    "    A = np.identity(3)\n",
    "    # Warp and crop the composite\n",
    "    croppedImage = cv2.warpPerspective(compImage, A, (outputWidth, accHeight), flags=cv2.INTER_LINEAR)\n",
    "    cv2.imwrite('croppedImage.jpg',croppedImage)\n",
    "    return croppedImage\n",
    "\n",
    "def getAccSize(ipv):\n",
    "    # Compute bounding box for the mosaic\n",
    "    minX = sys.maxsize\n",
    "    minY = sys.maxsize\n",
    "    maxX = 0\n",
    "    maxY = 0\n",
    "    channels = -1\n",
    "    width = -1  # Assumes all images are the same width\n",
    "    M = np.identity(3)\n",
    "    for i in ipv:\n",
    "        M = i.position\n",
    "        img = i.img\n",
    "        _, w, c = img.shape\n",
    "        if channels == -1:\n",
    "            channels = c\n",
    "            width = w\n",
    "\n",
    "        # BEGIN TODO 9\n",
    "        # add some code here to update minX, ..., maxY\n",
    "        #TODO-BLOCK-BEGIN\n",
    "        tmp_minX, tmp_minY, tmp_maxX, tmp_maxY = imageBoundingBox(img,M)\n",
    "        minX = min(tmp_minX, minX)\n",
    "        minY = min(tmp_minY, minY)\n",
    "        maxX = max(tmp_maxX, maxX)\n",
    "        maxY = max(tmp_maxY, maxY)\n",
    "        #TODO-BLOCK-END\n",
    "        # END TODO\n",
    "\n",
    "    # Create an accumulator image\n",
    "    accWidth = int(math.ceil(maxX) - math.floor(minX))\n",
    "    accHeight = int(math.ceil(maxY) - math.floor(minY))\n",
    "    print ('accWidth, accHeight:', (accWidth, accHeight))\n",
    "    translation = np.array([[1, 0, -minX], [0, 1, -minY], [0, 0, 1]])\n",
    "\n",
    "    return accWidth, accHeight, channels, width, translation\n",
    "\n",
    "\n",
    "def pasteImages(ipv, translation, blendWidth, accWidth, accHeight, channels):\n",
    "    acc = np.zeros((accHeight, accWidth, channels + 1))\n",
    "    # Add in all the images\n",
    "    M = np.identity(3)\n",
    "    for count, i in enumerate(ipv):\n",
    "        M = i.position\n",
    "        img = i.img\n",
    "\n",
    "        M_trans = translation.dot(M)\n",
    "        accumulateBlend(img, acc, M_trans, blendWidth)\n",
    "\n",
    "    return acc\n",
    "\n",
    "def normalizeBlend(acc):\n",
    "    \"\"\"\n",
    "       INPUT:\n",
    "         acc: input image whose alpha channel (4th channel) contains\n",
    "         normalizing weight values\n",
    "       OUTPUT:\n",
    "         img: image with r,g,b values of acc normalized\n",
    "    \"\"\"\n",
    "    # BEGIN TODO 11\n",
    "    # fill in this routine..\n",
    "    #TODO-BLOCK-BEGIN\n",
    "    h_acc = acc.shape[0]\n",
    "    w_acc = acc.shape[1]\n",
    "    img = np.zeros((h_acc, w_acc, 3))\n",
    "    for i in range(0, w_acc, 1):\n",
    "        for j in range(0, h_acc, 1):\n",
    "            if acc[j,i,3]>0:\n",
    "                img[j,i,0] = int (acc[j,i,0] / acc[j,i,3])\n",
    "                img[j,i,1] = int (acc[j,i,1] / acc[j,i,3])\n",
    "                img[j,i,2] = int (acc[j,i,2] / acc[j,i,3])\n",
    "            else:\n",
    "                img[j,i,0] = 0\n",
    "                img[j,i,1] = 0\n",
    "                img[j,i,2] = 0\n",
    "    img = np.uint8(img)\n",
    "    #TODO-BLOCK-END\n",
    "    # END TODO\n",
    "    return img\n",
    "\n",
    "def getDriftParams(ipv, translation, width):\n",
    "    # Add in all the images\n",
    "    M = np.identity(3)\n",
    "    for count, i in enumerate(ipv):\n",
    "        if count != 0 and count != (len(ipv) - 1):\n",
    "            continue\n",
    "\n",
    "        M = i.position\n",
    "\n",
    "        M_trans = translation.dot(M)\n",
    "\n",
    "        p = np.array([0.5 * width, 0, 1])\n",
    "        p = M_trans.dot(p)\n",
    "\n",
    "        # First image\n",
    "        if count == 0:\n",
    "            x_init, y_init = p[:2] / p[2]\n",
    "        # Last image\n",
    "        if count == (len(ipv) - 1):\n",
    "            x_final, y_final = p[:2] / p[2]\n",
    "\n",
    "    return x_init, y_init, x_final, y_final\n",
    "\n",
    "def computeDrift(x_init, y_init, x_final, y_final, width):\n",
    "    A = np.identity(3)\n",
    "    drift = (float)(y_final - y_init)\n",
    "    # We implicitly multiply by -1 if the order of the images is swapped...\n",
    "    length = (float)(x_final - x_init)\n",
    "    A[0, 2] = -0.5 * width\n",
    "    # Negative because positive y points downwards\n",
    "    A[1, 0] = -drift / length\n",
    "\n",
    "    return A\n",
    "\n",
    "def imageBoundingBox(img, M):\n",
    "    \"\"\"\n",
    "       This is a useful helper function that you might choose to implement\n",
    "       that takes an image, and a transform, and computes the bounding box\n",
    "       of the transformed image.\n",
    "\n",
    "       INPUT:\n",
    "         img: image to get the bounding box of\n",
    "         M: the transformation to apply to the img\n",
    "       OUTPUT:\n",
    "         minX: int for the minimum X value of a corner\n",
    "         minY: int for the minimum Y value of a corner\n",
    "         minX: int for the maximum X value of a corner\n",
    "         minY: int for the maximum Y value of a corner\n",
    "    \"\"\"\n",
    "    #TODO 8\n",
    "    #TODO-BLOCK-BEGIN\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "    p1 = np.array([0, 0, 1])\n",
    "    p2 = np.array([0, h-1, 1])\n",
    "    p3 = np.array([w-1, 0, 1])\n",
    "    p4 = np.array([w-1, h-1, 1])\n",
    "    \n",
    "    p1 = np.dot(M,p1)\n",
    "    p2 = np.dot(M,p2)\n",
    "    p3 = np.dot(M,p3)\n",
    "    p4 = np.dot(M,p4)\n",
    "\n",
    "    def roundup(x):\n",
    "        if x < 0.0:\n",
    "            x = math.floor(x)\n",
    "        else:\n",
    "            x = math.ceil(x)\n",
    "        return x\n",
    "    \n",
    "    # normalize when converting homogeneous coordinates back to Cartesian coordinates\n",
    "    # When Z is not 0 the point represented is the point (X/Z, Y/Z) in the Euclidean plane\n",
    "    \n",
    "    minX = roundup(min(p1[0]/p1[2], p2[0]/p2[2], p3[0]/p3[2], p4[0]/p4[2]))\n",
    "    minY = roundup(min(p1[1]/p1[2], p2[1]/p2[2], p3[1]/p3[2], p4[1]/p4[2]))\n",
    "    maxX = roundup(max(p1[0]/p1[2], p2[0]/p2[2], p3[0]/p3[2], p4[0]/p4[2]))\n",
    "    maxY = roundup(max(p1[1]/p1[2], p2[1]/p2[2], p3[1]/p3[2], p4[1]/p4[2]))\n",
    "    \n",
    "    return int(minX), int(minY), int(maxX), int(maxY)\n",
    "\n",
    "def accumulateBlend(img, acc, M, blendWidth):\n",
    "    \"\"\"\n",
    "       INPUT:\n",
    "         img: image to add to the accumulator\n",
    "         acc: portion of the accumulated image where img should be added\n",
    "         M: the transformation mapping the input image to the accumulator\n",
    "         blendWidth: width of blending function. horizontal hat function\n",
    "       OUTPUT:\n",
    "         modify acc with weighted copy of img added where the first\n",
    "         three channels of acc record the weighted sum of the pixel colors\n",
    "         and the fourth channel of acc records a sum of the weights\n",
    "    \"\"\"\n",
    "    # BEGIN TODO 10\n",
    "    # Fill in this routine\n",
    "    #TODO-BLOCK-BEGIN\n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    \n",
    "    h_acc = acc.shape[0]\n",
    "    w_acc = acc.shape[1]\n",
    "    \n",
    "    ## get the bounding box of img in acc\n",
    "    minX, minY, maxX, maxY = imageBoundingBox(img,M)\n",
    "  \n",
    "    for i in range(minX,maxX,1):\n",
    "        for j in range(minY,maxY,1):\n",
    "            # don't want to include black pixels when inverse warping\n",
    "            ## whether current pixel black or white\n",
    "            p = np.array([i, j, 1.])\n",
    "            p = np.dot(inv(M),p)\n",
    "            newx = min(p[0] / p[2], w-1)\n",
    "            newy = min(p[1] / p[2], h-1)\n",
    "            \n",
    "            if newx <0 or newx >= w or newy < 0 or newy >= h:\n",
    "                continue\n",
    "            if img[int(newy), int(newx), 0] == 0 and img[int(newy), int(newx), 1] ==0 and img[int(newy), int(newx), 2] == 0:\n",
    "                continue\n",
    "            if newx >= 0 and newx < w-1 and newy >= 0 and newy < h-1:    \n",
    "                weight = 1.0\n",
    "                if newx >= minX and newx < minX + blendWidth:\n",
    "                    weight = 1. * (newx - minX) / blendWidth\n",
    "                if newx <= maxX and newx > maxX - blendWidth:\n",
    "                    weight = 1. * (maxX - newx) / blendWidth\n",
    "                acc[j,i,3] += weight\n",
    "            \n",
    "                for k in range(3):\n",
    "                    acc[j,i,k] += img[int(newy),int(newx),k] * weight      \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # images = [cv2.imread('yosemite1.jpg'), cv2.imread('yosemite2.jpg'), cv2.imread('yosemite3.jpg'), cv2.imread('yosemite4.jpg')]\n",
    "    images = [cv2.imread('carmel1.png'), cv2.imread('carmel2.png'), cv2.imread('carmel3.png'), cv2.imread('carmel4.png')]\n",
    "\n",
    "    # Generate \n",
    "    t = np.eye(3); ipv = []; inmatches = [];\n",
    "    for i in range(0,len(images)-1):\n",
    "        ipv.append(ImageInfo('',images[i], np.linalg.inv(t)))\n",
    "        t = computeMapping(images[i], images[i+1]).dot(t)\n",
    "    ipv.append(ImageInfo('',images[len(images)-1], np.linalg.inv(t)))\n",
    "    print(f'Mapping Matrix:\\n {t}')\n",
    "    # Blend Image\n",
    "    blendImages(ipv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
